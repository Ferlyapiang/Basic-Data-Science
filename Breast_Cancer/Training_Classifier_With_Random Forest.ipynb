{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidak Kenal maka Tidak Sayang\n",
    "\n",
    "- Nama : Ferly Jeremi Purnawan Apiang\n",
    "- NRP : 1973005\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Classifier Random Forest\n",
    "\n",
    "Pemanggilan Dataset Breast Cancer dengan menggunakan Training Classifier **Random Forest**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Breast Cancer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensi Feature: (569, 30)\n",
      "Class: {0, 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "print(f'Dimensi Feature: {X.shape}')\n",
    "print(f'Class: {set(y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pertama Lakukan pemanggilan dengan memanggil datasetnya (import load_breast_cancer)\n",
    "- Panggil loadnya dengan menanampungnya ke dalam variable yang saya beri nama X dan y\n",
    "- Lalu saya ingin mengetahui dimensi dari datasetnya saya panggil Print X.shape dan set{y} untuk class.\n",
    "\n",
    "Hasil yang dikeluarkan yaitu Data Feature adalah (569, 30) terdapat 569 Baris dan 30 kolom. Lalu dengan class pada target labelnya terdapat {0, 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training dan Testing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita akan mencoba melakukan ke dalam sebuah training set dan testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Penggunaan Model Sklearn \"from sklearn.model_selection lalu untuk Testing kita import train_test_split\".\n",
    "- Lalu kita panggil train_test_split nya, lalu kita sertakan X dan y (variable masing-masing) sebagai parameternya.\n",
    "- Lalu terkait parameter test_size nya kita set sebagai 0.25 yang artinya disini testing set nya akan menempati 25% dari total keseluruhan dataset yang kita miliki.\n",
    "- Lalu berikutnya untuk random_state kita beri nilai 0.\n",
    "- Pemanggilan fungsi train_test_split ini akan menghasilkan 4 kumpulan data, keempatnya perlu ditampung ke dalam 4 buah variabel yaitu X_train, X_test, y_train, dan y_test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification **RandomForestClassifier** dengan Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "menerapkan Random Forest untuk melakukan klasifkasi Breast Cancer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=150, random_state=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=150, \n",
    "                               random_state=0)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pertama-tama kita akan mengimport terlebihi dahulu modulnya dengan memanggil method *'from sklearn.ensemble import RandomForestClassifier'*.\n",
    "- Selanjutnya kita akan bentuk objek dari *'RandomForestClassifier'* ini dengan menyertakan 2 buah parameter yaitu *'(n_estimators=150)'* yang untuk kasus kali ini kita melakukan training 150 buah model.\n",
    "- Lalu agar eksperimen kita ini bisa kita replicate dengan hasil yang konsisten, kita juga perlu mengeset random statenya yang dalam kasus kita kali ini adalah *'(random_state=0)'*. \n",
    "- Selanjutnya objek yang terbentuk tersbut akan kita tampung kedalam variabel *model*. \n",
    "- Untuk selanjutnya, model ini akan kita training dengan memanggil method *fit* dengan menyertakan parameter *'(X_train, y_train)'*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluasi Model\n",
    "\n",
    "Disini kita akan lakukan evaluasi performa dari model **Random Forest** yang baru saja kita training tadi dengan memanfaatkan **Classification Report**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96        53\n",
      "           1       0.99      0.97      0.98        90\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.97      0.97      0.97       143\n",
      "weighted avg       0.97      0.97      0.97       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pertama-tam kita akan import terlebih dahulu modulnya dengan memanggil *'from sklearn.metrics import classification_report'*.\n",
    "- Lalu berikutnya kita lakukan prediksi terhadap x_test dengan memanggil *'model.predict(X_test)'* yang akan kita tampung kedalam variabel *y_pred*.\n",
    "- Untuk selanjutnya kita akan memanggil *'classification_report'* dengan menyertakan parameter *'(y_test, y_pred)'*.\n",
    "\n",
    "Hasil output merupakan **classification report** sebagai bentuk evaluasi terhadap model **Random Forest** yang baru saja kita training sebelumnya, ditampilkan nilai *precision*, *recall*, serta *f1-score* nya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferly\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ferly\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow0_col0,#T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow0_col1,#T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow0_col2{\n",
       "            background-color:  #440154;\n",
       "            color:  #f1f1f1;\n",
       "        }#T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow1_col0,#T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow1_col1,#T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow1_col2{\n",
       "            background-color:  #fde725;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057faf\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >precision</th>        <th class=\"col_heading level0 col1\" >recall</th>        <th class=\"col_heading level0 col2\" >f1-score</th>        <th class=\"col_heading level0 col3\" >support</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057faflevel0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow0_col0\" class=\"data row0 col0\" >0.866667</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow0_col1\" class=\"data row0 col1\" >0.866667</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow0_col2\" class=\"data row0 col2\" >0.866667</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow0_col3\" class=\"data row0 col3\" >30</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057faflevel0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow1_col0\" class=\"data row1 col0\" >0.966667</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow1_col1\" class=\"data row1 col1\" >0.966667</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow1_col2\" class=\"data row1 col2\" >0.966667</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow1_col3\" class=\"data row1 col3\" >30</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057faflevel0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow2_col0\" class=\"data row2 col0\" >0.870968</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow2_col1\" class=\"data row2 col1\" >1.000000</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow2_col2\" class=\"data row2 col2\" >0.931034</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow2_col3\" class=\"data row2 col3\" >27</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057faflevel0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow3_col0\" class=\"data row3 col0\" >0.862069</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow3_col1\" class=\"data row3 col1\" >0.892857</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow3_col2\" class=\"data row3 col2\" >0.877193</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow3_col3\" class=\"data row3 col3\" >28</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057faflevel0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow4_col0\" class=\"data row4 col0\" >0.900000</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow4_col1\" class=\"data row4 col1\" >0.794118</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow4_col2\" class=\"data row4 col2\" >0.843750</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow4_col3\" class=\"data row4 col3\" >34</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057faflevel0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow5_col0\" class=\"data row5 col0\" >0.967742</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow5_col1\" class=\"data row5 col1\" >0.810811</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow5_col2\" class=\"data row5 col2\" >0.882353</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow5_col3\" class=\"data row5 col3\" >37</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057faflevel0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow6_col0\" class=\"data row6 col0\" >1.000000</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow6_col1\" class=\"data row6 col1\" >0.966667</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow6_col2\" class=\"data row6 col2\" >0.983051</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow6_col3\" class=\"data row6 col3\" >30</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057faflevel0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow7_col0\" class=\"data row7 col0\" >0.900000</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow7_col1\" class=\"data row7 col1\" >0.900000</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow7_col2\" class=\"data row7 col2\" >0.900000</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow7_col3\" class=\"data row7 col3\" >30</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057faflevel0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow8_col0\" class=\"data row8 col0\" >0.800000</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow8_col1\" class=\"data row8 col1\" >0.923077</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow8_col2\" class=\"data row8 col2\" >0.857143</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow8_col3\" class=\"data row8 col3\" >26</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057faflevel0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow9_col0\" class=\"data row9 col0\" >0.933333</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow9_col1\" class=\"data row9 col1\" >1.000000</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow9_col2\" class=\"data row9 col2\" >0.965517</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow9_col3\" class=\"data row9 col3\" >28</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057faflevel0_row10\" class=\"row_heading level0 row10\" >accuracy</th>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow10_col0\" class=\"data row10 col0\" >0.906667</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow10_col1\" class=\"data row10 col1\" >0.906667</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow10_col2\" class=\"data row10 col2\" >0.906667</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow10_col3\" class=\"data row10 col3\" >0</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057faflevel0_row11\" class=\"row_heading level0 row11\" >macro avg</th>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow11_col0\" class=\"data row11 col0\" >0.906745</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow11_col1\" class=\"data row11 col1\" >0.912086</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow11_col2\" class=\"data row11 col2\" >0.907337</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow11_col3\" class=\"data row11 col3\" >300</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057faflevel0_row12\" class=\"row_heading level0 row12\" >weighted avg</th>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow12_col0\" class=\"data row12 col0\" >0.909979</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow12_col1\" class=\"data row12 col1\" >0.906667</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow12_col2\" class=\"data row12 col2\" >0.906152</td>\n",
       "                        <td id=\"T_f4ce9feb_da97_11eb_8e05_ec086b057fafrow12_col3\" class=\"data row12 col3\" >300</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x26a99931850>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=30,\n",
    "                           n_informative=12,\n",
    "                           n_clusters_per_class=1, n_classes=10,\n",
    "                           class_sep=2.0, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y)\n",
    "\n",
    "\n",
    "clf = LogisticRegressionCV(max_iter=1000, random_state=42).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(classification_report(clf.predict(X_test), \n",
    "                                        y_test, digits=2,\n",
    "                                        output_dict=True)).T\n",
    "\n",
    "df['support'] = df.support.apply(int)\n",
    "\n",
    "df.style.background_gradient(cmap='viridis',\n",
    "                             subset=pd.IndexSlice['0':'1', :'f1-score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- langka pemanggilan ada banyak sekali tapi kalian bisa lihat saya sudah memisahkan apa-apa saja yang perlu diimport.\n",
    "- Masuk untuk membuat classification Dengan menentukan samples saya memberi batas 1000 lalu, featuresnya saya beri jarak 30.\n",
    "- df.suport.apply fungsinya untuk menentukan berapa kemungkinan orang yang terkena.\n",
    "\n",
    "Ya jadi demikian Training Classifier menggunakan **Random Forest dengan Breast Cancer Dataset**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
